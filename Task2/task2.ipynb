{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsgDtNm_qD3L"
      },
      "source": [
        "## NAME: VIJAY KRISHNA A B\n",
        "## POSITION: DATA SCIENCE INTERN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBZH-h-bqLlI"
      },
      "source": [
        "### TASK: NEXT WORD PREDICTION USING RNN LSTM MODEL\n",
        "### DIFFICULTY: ADVANCED LEVEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsXht7GOn1zy"
      },
      "source": [
        "### IMPORTING THE NECESSARY MODULES\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5DqCgSz8vCr"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFxhWtYYoAo9"
      },
      "source": [
        "### UPLOAD THE DATASET\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "yYlbymQD9PK7",
        "outputId": "ded7d751-22f0-4c9d-b1d5-edc121e30789"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3c59e311-b40e-4b4f-bfc9-8b15d36073f0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3c59e311-b40e-4b4f-bfc9-8b15d36073f0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 1661-0.txt to 1661-0.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq51UGvjoFar"
      },
      "source": [
        "### PREPROCESS THE DATA BY REPLACING UNWANTED CHARACTERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "lbxre34N9gyI",
        "outputId": "50acca57-0988-4bc5-a9cc-f65b20492543"
      },
      "source": [
        "file = open('1661-0.txt', 'r', encoding = 'utf8')\n",
        "\n",
        "lines = []\n",
        "for i in file:\n",
        "  lines.append(i)\n",
        "\n",
        "#print(lines[0:50])\n",
        "\n",
        "data = \"\"\n",
        "for i in lines:\n",
        "  data = ' '.join(lines)\n",
        "\n",
        "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '').replace('’', '').replace('‘', '').replace('“', '').replace('”', '')\n",
        "\n",
        "data = data.split()\n",
        "data = ' '.join(data)\n",
        "data[:500]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Project Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan Doyle This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.net Title: The Adventures of Sherlock Holmes Author: Arthur Conan Doyle Release Date: November 29, 2002 [EBook #1661] Last Updated: May 20, 2019 Language: English Character set en\""
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCr3fO40_MPY",
        "outputId": "ace067c6-942a-4062-ff66-e9b695c13856"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "572175"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2Xh8g7boODS"
      },
      "source": [
        "### USE TOKENIZER TO CONVERT TEXT TO SEQUENCES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CGY9Gck_dSQ",
        "outputId": "9b672242-d5c4-4631-9ea2-bd7402bd4502"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "\n",
        "pickle.dump(tokenizer, open('token.pkl', 'wb'))\n",
        "\n",
        "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
        "print(sequence_data[:15])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[141, 4615, 1, 977, 5, 125, 32, 45, 542, 2155, 2156, 27, 978, 14, 22]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2wgdEloAYGw",
        "outputId": "c6f45e70-b641-4098-827d-4dd11f344e9d"
      },
      "source": [
        "len(sequence_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "108547"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3ccZzXAAvvY",
        "outputId": "d2e18a55-135a-4af8-980a-1710859d5a26"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8431"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yChADgqdD0fO",
        "outputId": "ad56b267-1909-44cc-fb70-7e9abc584678"
      },
      "source": [
        "sequence_length = 10\n",
        "sequences = []\n",
        "\n",
        "for i in range(sequence_length, len(sequence_data)):\n",
        "  words = sequence_data[i-sequence_length : i+1]\n",
        "  sequences.append(words)\n",
        "\n",
        "sequences = np.array(sequences)\n",
        "sequences[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 141, 4615,    1,  977,    5,  125,   32,   45,  542, 2155, 2156],\n",
              "       [4615,    1,  977,    5,  125,   32,   45,  542, 2155, 2156,   27],\n",
              "       [   1,  977,    5,  125,   32,   45,  542, 2155, 2156,   27,  978],\n",
              "       [ 977,    5,  125,   32,   45,  542, 2155, 2156,   27,  978,   14],\n",
              "       [   5,  125,   32,   45,  542, 2155, 2156,   27,  978,   14,   22],\n",
              "       [ 125,   32,   45,  542, 2155, 2156,   27,  978,   14,   22,    1],\n",
              "       [  32,   45,  542, 2155, 2156,   27,  978,   14,   22,    1,  263],\n",
              "       [  45,  542, 2155, 2156,   27,  978,   14,   22,    1,  263,    5],\n",
              "       [ 542, 2155, 2156,   27,  978,   14,   22,    1,  263,    5,  382],\n",
              "       [2155, 2156,   27,  978,   14,   22,    1,  263,    5,  382, 2157]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlzZqjLxob-P"
      },
      "source": [
        "### SEPEARATE THE DEPENDANT AND INDEPENDANT VALUES IN NUMPY ARRAYS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60khY8SkE_Cv",
        "outputId": "ed55f131-4816-4864-904a-b5c3d4fcd522"
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for seq in sequences:\n",
        "  X.append(seq[:sequence_length])\n",
        "  y.append(seq[sequence_length])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"X:\", X[:10])\n",
        "print(\"y:\", y[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: [[ 141 4615    1  977    5  125   32   45  542 2155]\n",
            " [4615    1  977    5  125   32   45  542 2155 2156]\n",
            " [   1  977    5  125   32   45  542 2155 2156   27]\n",
            " [ 977    5  125   32   45  542 2155 2156   27  978]\n",
            " [   5  125   32   45  542 2155 2156   27  978   14]\n",
            " [ 125   32   45  542 2155 2156   27  978   14   22]\n",
            " [  32   45  542 2155 2156   27  978   14   22    1]\n",
            " [  45  542 2155 2156   27  978   14   22    1  263]\n",
            " [ 542 2155 2156   27  978   14   22    1  263    5]\n",
            " [2155 2156   27  978   14   22    1  263    5  382]]\n",
            "y: [2156   27  978   14   22    1  263    5  382 2157]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZITOgFWFG4C",
        "outputId": "5d772909-581b-49c3-b2d2-7a78f6473d0e"
      },
      "source": [
        "y = to_categorical(y, num_classes = vocab_size)\n",
        "y[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnYYHoJ5o3AS"
      },
      "source": [
        "### BUILD THE MODEL WITH\n",
        "\n",
        "> EMBEDDING LAYER\n",
        "\n",
        "> LSTM(X2)\n",
        "\n",
        "> DENSE(X2)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycMzQg-6M4ID"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 10, input_length = sequence_length))\n",
        "model.add(LSTM(1000, return_sequences = True))\n",
        "model.add(LSTM(1000))\n",
        "model.add(Dense(1000, activation = 'relu'))\n",
        "model.add(Dense(vocab_size, activation = 'softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-weMoL1gNhMF",
        "outputId": "9d076b48-0528-4753-8ed4-70ea10df8549"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 10, 10)            84310     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 10, 1000)          4044000   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 1000)              8004000   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8431)              8439431   \n",
            "=================================================================\n",
            "Total params: 21,572,741\n",
            "Trainable params: 21,572,741\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAxia0CjpccE"
      },
      "source": [
        "### CREATE MODEL CHECKPOINT AND TRAIN THE MODEL WITH CATEGORICAL CROSS ENTROPY LOSS AND ADAM OPTIMIZER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Whz8CN7vYmRZ",
        "outputId": "41341f1a-680b-44c7-930f-0023bd411ef9"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint('next_words.h5', monitor='loss', verbose=1, save_best_only = True)\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate = 0.001))\n",
        "model.fit(X, y, epochs = 15, batch_size = 64, callbacks = [checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1696/1696 [==============================] - 104s 56ms/step - loss: 6.4130\n",
            "\n",
            "Epoch 00001: loss improved from inf to 6.41305, saving model to next_words.h5\n",
            "Epoch 2/15\n",
            "1696/1696 [==============================] - 95s 56ms/step - loss: 5.8329\n",
            "\n",
            "Epoch 00002: loss improved from 6.41305 to 5.83293, saving model to next_words.h5\n",
            "Epoch 3/15\n",
            "1696/1696 [==============================] - 95s 56ms/step - loss: 5.4796\n",
            "\n",
            "Epoch 00003: loss improved from 5.83293 to 5.47957, saving model to next_words.h5\n",
            "Epoch 4/15\n",
            "1696/1696 [==============================] - 95s 56ms/step - loss: 5.2099\n",
            "\n",
            "Epoch 00004: loss improved from 5.47957 to 5.20990, saving model to next_words.h5\n",
            "Epoch 5/15\n",
            "1696/1696 [==============================] - 95s 56ms/step - loss: 4.9857\n",
            "\n",
            "Epoch 00005: loss improved from 5.20990 to 4.98575, saving model to next_words.h5\n",
            "Epoch 6/15\n",
            "1696/1696 [==============================] - 95s 56ms/step - loss: 4.7791\n",
            "\n",
            "Epoch 00006: loss improved from 4.98575 to 4.77909, saving model to next_words.h5\n",
            "Epoch 7/15\n",
            "1696/1696 [==============================] - 95s 56ms/step - loss: 4.5747\n",
            "\n",
            "Epoch 00007: loss improved from 4.77909 to 4.57470, saving model to next_words.h5\n",
            "Epoch 8/15\n",
            "1696/1696 [==============================] - 95s 56ms/step - loss: 4.3597\n",
            "\n",
            "Epoch 00008: loss improved from 4.57470 to 4.35970, saving model to next_words.h5\n",
            "Epoch 9/15\n",
            "1696/1696 [==============================] - 95s 56ms/step - loss: 4.1153\n",
            "\n",
            "Epoch 00009: loss improved from 4.35970 to 4.11532, saving model to next_words.h5\n",
            "Epoch 10/15\n",
            "1696/1696 [==============================] - 95s 56ms/step - loss: 3.8218\n",
            "\n",
            "Epoch 00010: loss improved from 4.11532 to 3.82182, saving model to next_words.h5\n",
            "Epoch 11/15\n",
            "1696/1696 [==============================] - 95s 56ms/step - loss: 3.4507\n",
            "\n",
            "Epoch 00011: loss improved from 3.82182 to 3.45073, saving model to next_words.h5\n",
            "Epoch 12/15\n",
            "1696/1696 [==============================] - 95s 56ms/step - loss: 2.9899\n",
            "\n",
            "Epoch 00012: loss improved from 3.45073 to 2.98987, saving model to next_words.h5\n",
            "Epoch 13/15\n",
            "1696/1696 [==============================] - 95s 56ms/step - loss: 2.4557\n",
            "\n",
            "Epoch 00013: loss improved from 2.98987 to 2.45570, saving model to next_words.h5\n",
            "Epoch 14/15\n",
            "1696/1696 [==============================] - 95s 56ms/step - loss: 1.8898\n",
            "\n",
            "Epoch 00014: loss improved from 2.45570 to 1.88984, saving model to next_words.h5\n",
            "Epoch 15/15\n",
            "1696/1696 [==============================] - 95s 56ms/step - loss: 1.3534\n",
            "\n",
            "Epoch 00015: loss improved from 1.88984 to 1.35336, saving model to next_words.h5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faee99de250>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7K2JWt3psns"
      },
      "source": [
        "### LOAD THE MODEL AND THE TOKENIZER FOR PREDICTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WErO0QPhdEm",
        "outputId": "6aeb873b-05a2-4c81-a6b7-1bff14ec74c3"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "model = load_model(\"next_words.h5\")\n",
        "tokenizer = pickle.load(open('token.pkl', 'rb'))\n",
        "\n",
        "model.evaluate(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3392/3392 [==============================] - 61s 17ms/step - loss: 0.8078\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8078064918518066"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkY5O2WNp0Rx"
      },
      "source": [
        "### PREDICTION:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq9WWeHoiEQN"
      },
      "source": [
        "def predict_next_word(model, tokenizer, text):\n",
        "  sequence = tokenizer.texts_to_sequences([text])\n",
        "  sequence = np.array(sequence)\n",
        "\n",
        "  pred = np.argmax(model.predict(sequence))\n",
        "  predicted = \"\"\n",
        "  for key, value in tokenizer.word_index.items():\n",
        "    if value == pred:\n",
        "      predicted  = key\n",
        "      break\n",
        "\n",
        "  #print(predicted)\n",
        "  return predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQhcHmwnkjOB",
        "outputId": "d6fcbee3-9269-4a30-b9f2-e52220184025"
      },
      "source": [
        "to_predict = \"At the end of the performance the actor looked very\"\n",
        "print(predict_next_word(model, tokenizer, to_predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "little\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrBFdtFFlgdZ",
        "outputId": "bcff5b63-c7af-449b-9396-30ded21c8cf9"
      },
      "source": [
        "to_predict = \"By the time you learn your lessons I will be\"\n",
        "print(predict_next_word(model, tokenizer, to_predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trying\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LCAPVFMmjbg",
        "outputId": "4b568256-4ec6-4414-c439-d96f1aacc6d7"
      },
      "source": [
        "to_predict = \"It will be fun to go there and have a\"\n",
        "print(predict_next_word(model, tokenizer, to_predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "marriage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0E1CSxrm18n",
        "outputId": "0a46adbb-36a1-42a7-b40a-b8718951e725"
      },
      "source": [
        "to_predict = \"The children were woken up by the noise in the\"\n",
        "print(predict_next_word(model, tokenizer, to_predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "garden\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vzzg1EFnCP0",
        "outputId": "2f602221-b80b-4d40-b59a-45d76a1b0fbd"
      },
      "source": [
        "to_predict = \"I forgot to tell you that you received a message from him. It is on your\"\n",
        "print(predict_next_word(model, tokenizer, to_predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pride\n"
          ]
        }
      ]
    }
  ]
}